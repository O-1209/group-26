---
title: "Marvel Comics Characters Combat Analysis"
author: "Group_26"
date: "2021/6/23"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries,echo = FALSE ,include=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(moderndive)
library(gapminder)
library(skimr)
library(tidyverse)
library(kableExtra)
library(gridExtra)
library(corrplot)
```

```{r data, echo = FALSE, eval = TRUE}
marvel <- read.csv('C:/Users/lc1998/Desktop/marvel(2).csv')
marvel <- marvel[-c(1,12,13)] #delete extra columns
marvel <- na.omit(marvel)   #delete NA
```

# Introduction {#sec:Intro}
Marvel Comics have created many classic characters, but how do we evaluate the effectiveness in combat of these super heroes? This poster will display graphical and numerical summaries of the heroes' characteristic data, investigating the relationship between their combat score and their basic features.

# Basic Analysis {#sec:Basic}

## Data processing

+ Variables explanation  

  **-Explanatory variable**  
Gender(binary variable): female, male and unknown(as some of the heroes are not human)  
Height, weight: hero physical features   
Intelligence, strength,	speed, durability, power: hero abilities  

  **-Outcome variable**  
Combat: hero fighting force  

+ Missing and abnormal data procedure  
  
  For the missing value, the character is omitted from analysis.  
For the abnormal data, e.g. some unknown gender heroes or some heroes with negative value height and weight, i.e.-99, they are all kept in this analysis due to the particularity of the Marvel heroes in virtual movies and novels, for example, they may not be 3D characters or might be from some specific species, such as Mutant, Eternal.

## Numerical and graphical Summaries

+ Outcome varibale summaries 

```{r combat numerical summary,echo=FALSE}
marvel%>%
  summarise(n=n(),Mean=round(mean(Combat),digits=1), 
    St.Dev=round(sd(Combat),digits=1), Min=min(Combat), 
    Q1 = quantile(Combat,0.25), Median=median(Combat), 
    Q3 = quantile(Combat,0.75), Max=max(Combat)) %>%
 kable(caption = '\\label{tab:summaries} Summary statistics on the combat') %>%
 kable_styling(font_size = 10, latex_options = "hold_position")
```

```{r boxplot, echo = FALSE, out.width='50%',fig.align="center",fig.cap = "\\label{fig:box} boxplot of combat."}
boxplot(marvel$Combat, main="Combat", ylab = "Score" )
```
  Combining the summary statistics and the boxplot, the combat values are mostly between 10 and 70 with mean 47.5 and median 56.

+ Explanatory variables summaries

```{r summary1, echo= FALSE, eval=TRUE}
my_skim <- skim_with(base = sfl(n = length))
marvel[,-c(1,2)]%>%
  my_skim() %>%
  transmute(Variable=skim_variable, n=n, Mean=numeric.mean, SD=numeric.sd,
            Min=numeric.p0, Median=numeric.p50,  Max=numeric.p100, 
            IQR = numeric.p75-numeric.p50) %>%
  knitr::kable(caption = '\\label{tab:summary} Summary Statistics.',
               booktabs = TRUE, linesep = "",digits = 2) %>%
  kable_styling(font_size = 10, latex_options = "hold_position")
```

```{r boxplot1,echo = FALSE, out.width='50%',fig.align="center"}
par(mfrow=c(1,2)) 
boxplot(marvel$Height,main="Height",col=6, ylab = "Score")
boxplot(marvel$Weight,main="Weight",col=7, ylab = "Score")
par(mfrow=c(1,1)) 
marvel_ability<-marvel%>%
  select(Intelligence:Power)
boxplot(marvel_ability,col=c(2:6), ylab = "Score")
```

+ Star plot of the powerful heroes 

```{r starplot, echo=FALSE, out.width='80%',fig.align="center"}
#Star plot
marvel.Star <- read.csv('C:/Users/lc1998/Desktop/marvel(2).csv')
marvel.Star.Names <- marvel.Star[,-c(1,3)] %>%
  filter(Combat==101 | Combat==100) %>%
  select(Name)
marvel.Star.Mtrix <- marvel.Star[,-c(1,2,3)] %>%
  filter(Combat==101 | Combat==100) %>%
  as.matrix()# as.numeric()#101 & 100 data
rownames(marvel.Star.Mtrix) <- marvel.Star.Names[,1]
stars(marvel.Star.Mtrix,draw.segments = T,full = F,key.loc=c(8.5,1.5))
```

This is the star plot, which visualises the all-round data and indicators of one specific hero in the marvel data set.The star plot displays these 14 heroes, with the highest combat score (101, Ares) and the combat score of the second-ranked 13 heroes (100, 13 heroes). In the plot, it is clear that Ares is the most powerful and unbeatable hero with omnipotent ability, and most of these heroes have a high score of intelligence OR speed. 

+ Correlation plot of the corvariates

```{r visualisation, echo=FALSE, eval=TRUE, out.width='80%',fig.align="center"}
cor <- cor(marvel[,-c(1,2)])
corrplot(corr = cor , method ='number' ,type='upper',order='hclust') #cor matrix
```

```{r visualisation2, echo=FALSE, eval=FALSE}
cor <- cor(marvel[,-c(1,2)])
corrplot(corr = cor , method ='circle' ,type='upper',order='hclust') #cor matrix, this plot is used into poster.
```

 From the correlation plot, 7 explanatory variables have a strong relationship with the response variable, thus a linear regression model will be built and we will explore the confidence intervals of the parameters. Also, there is another problem which we can see from the correlation plot. We can see that intelligence, durability and power have the most significance positive correlations with combat, 0.76, 0.68 and 0.66 respectively. Thus, it is reasonable to consider that there is multicollinearity because of the strong positive correlations between the explanatory variables.

# Model Investigation

## Building an initial linear regression model

Firstly, we build a linear model as following,  

$Y_{Combat} = \alpha + \beta_{1} * X_{Gender} + \beta_{2} * X_{Height} + \beta_{3} * X_{Weight} + \beta_{4} * X_{Intelligence} + \beta_{5} * X_{Strength} + \beta_{6} * X_{Speed} + \beta_{7} * X_{Durability} + \beta_{8} * X_{Power} + \epsilon$


```{r simple linear model, echo = FALSE, warning=FALSE}
model<- lm(Combat ~ Gender + Height + Weight + Intelligence + Strength + Speed + 
           Durability+ Power, data = marvel)
get_regression_table(model, print = TRUE)
```
  
From the regression table, we notice that half of the parameters in the full model are not
significant due to the multicollinearity, thus stepwise regression is used to address this problem. 

## Stepwise regression 

The following code shows the stepwise regession, which is used to select which variables will be kept in the model.

```{r stepwise regression,include=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(olsrr)
library(GGally)

backwardmodel.1 <- step(model,method = "backward")   #using the backward method
```

```{r backforwardmodel, echo=FALSE,warning=FALSE}
get_regression_table(backwardmodel.1, print = TRUE)
```

  From the stepwise regression method for model selection, using AIC as out criterion, 3 predictors are dropped from the model. Only height, weight, intelligence, speed and durability are kept in the model. We then use the p-value to do further model selection.

```{r p-value,include=FALSE}
#reduced model
marvel.step <- lm(formula = Combat ~ Height + Weight + Intelligence + Speed + 
                    Durability, data = marvel)
summary(marvel.step)

#drop 'Speed' variable based on p-value
model2 <- lm(formula = Combat ~ Height + Weight + Intelligence + 
               Durability, data = marvel)
summary(model2)

#drop 'Weight' based on p-value
model3 <- lm(formula = Combat ~ Height + Intelligence + 
               Durability, data = marvel)
summary(model3)
```

This selection procedure repeatedly drops the least significant variable (i.e. p-value is greater than 0.05) one by one, then generates a new model,
until all parameters are significant. Finally we got the model as following.

$Y_{Combat}=\alpha+ \beta_1* X_{Height}+\beta_2* X_{Intelligence}+\beta_3* X_{Durability}$  

```{r final.result, echo=FALSE}
get_regression_table(model3, print = TRUE)
```

  Here we end up with a model with three explanatory variables: height, intelligence and durability. The $R^2$ value is 63.8% in the new model, which indicates that the new model is a plausible fit.

## Checking assumption

+ Checking the influential point

```{r outliers judgment, echo=FALSE, out.width='80%',fig.align="center"}
par(mfrow=c(2,2)) 
plot(model3)
cook<-cooks.distance(model3)
n <- length(cook)
model3_data <- marvel %>%
  select(Height, Intelligence, Durability, Combat) %>%
  mutate('cook_distance' = cook) %>%
  filter(cook_distance <= 4/n)
```
From the Figure 4, which displays our plots for checking residuals, we discover that there are some influential points (Abnormalities of Cook's value), so we delete these influential observations from the original data set. Then, we refit the model excluding using the same significant explanatory variables to estimate the parameters of the model. 

+ Checking model assumption
```{r final model analysis step1, include=FALSE}
model4 <- lm(formula = Combat ~ Height + Intelligence + 
               Durability, data = model3_data)
summary(model4)
```

```{r,echo=FALSE,fig.align="center",out.width='80%'}
par(mfrow=c(2,2)) 
plot(model4) 
```

1. From the Residuals vs Fitted plot, the residuals are randomly scattered around the zero line with no significant pattern, so it is plausible to make the assumption that the residuals are normally distributed with mean zero and constant variance.  
2. The normal Q-Q plot shows that the points follow the straight line very well suggesting that it is reasonable to assume the errors are normally distributed.  
3. The Scale-Location plot displays that the points are randomly distributed around the red line, and the red line does not show an obvious trend, so the variance assumption is plausible.  
4. The cook's distance plot shows that there are not obvious outliers that might influence the regression model.  

```{r final.result1, echo=FALSE}
get_regression_table(model4, print = TRUE)
```

However, it can be seen that in the new model the p-value of the intercept is 0.07337, which is greater than 0.05, so we will exclude the intercept and refit the model.

+ Checking point estimation

```{r final model analysis step2, include=FALSE}
model5 <- lm(formula = Combat ~ Height + Intelligence + Durability-1, data = model3_data)
summary(model5)
confint(model5)
```

```{r confidence interval,echo=FALSE,out.width='70%',fig.align="center"}
ggcoef(model5,vline_color = "red",
       vline_linetype = "solid",
       errorbar_color = "blue",
       errorbar_height = .25, exclude_intercept = TRUE)
```

|               |   2.5%            | 97.5%        
|:-------------:|:-----------------:|:------------:          
|  Height       |   0.02787830      | 0.06496256      
|  Intelligence |   0.62906405      | 0.81891628 
|  Durability   |   0.05010371      | 0.21935237   

Here are the confidence intervals of the coefficients. It can be seen that the intervals of height, intelligence and durability are not include 0 and all greater than 0, which means that these three predictors are significant enough to retain. 

Thus, we get the final moedel as following,  
$Y_{Combat}=0.046* X_{Height}+0.724* X_{Intelligence}+0.135* X_{Durability} + \epsilon$

```{r final.result2, echo=FALSE}
get_regression_table(model5, print = TRUE)
```

## Model checking using other method of stepwise selection 

  In the above discussion, we use backward stepwise regression to select the variables. Now we use another method of stepwise regression, which is combining forward and backward selection, to check whether the model from backward is the same as the model from combining forward and backward selection.

```{r based on AIC, include=FALSE}
model.selection <- ols_step_both_aic(model,details = TRUE)
summary(model.selection$model)
model.selection[c("predictors","method","aic","rss","arsq","steps")]
```

```{r base on p value, include=FALSE}
model.selection_p <- ols_step_both_p(model,details = TRUE, pent=0.05,prem = 0.05)
summary(model.selection_p$model)
model.selection_p[c("predictors","method","aic","rss","arsq","steps")]
```

  Finally combining the forward and backward model selection method, the final models are the same.

# Further Task {#sec:Fur}

  Is there any difference between females combat and males combat? We will investigate this question by via a boxplot and hypothesis test.

```{r male data,include=FALSE}
marvel.Male <- marvel %>%
  filter(Gender=='Male')%>%
  select(Combat) %>%
  as.matrix() %>%
  as.numeric()
```

```{r female data,include=FALSE}
marvel.Female <- marvel %>%
  filter(Gender=='Female') %>%
  select(Combat) %>%
  as.matrix() %>%
  as.numeric()
```

```{r numerical summary, include=FALSE}
summary(marvel.Male)
summary(marvel.Female)
```

```{r summary statistics, echo=FALSE, eval=TRUE}
marvel %>%
  group_by(Gender) %>%
  summarise(n=n(),Mean=round(mean(Combat),digits=1),St.Dev=round(sd(Combat),digits=1),
            Min=min(Combat), Q1 = quantile(Combat,0.25), Median=median(Combat),
            Q3 = quantile(Combat,0.75), Max=max(Combat)) %>%
  kable(caption = '\\label{tab:summaries} Summary statistics on combat by gender of super heroes') %>%
  kable_styling(latex_options = "hold_position")
```

```{r boxplots,echo=FALSE, out.width='70%',fig.align="center"}
ggplot(data = marvel, mapping = aes(x = Gender, y = Combat)) +
  geom_boxplot(fill = "steelblue") +
  labs(x = "Gender", y = "Combat",
        title = "The Combat Effectiveness of Super Heroes in Marvel by Gender")
```

  From the boxplot, the median of the unknown gender heroes is nearly zero, and the IQR range is between 0 and 45 approximately. The female heroes combat IQR covers a largest range, from 1 to 70 with median 53. And the male heroes seem have stronger ability performance, IQR range is 28 to 80 with median 58.

  Then we use a non parametric hypothesis test to investigate the difference between the female combat and male combat.

```{r hypothesis test,echo=TRUE}
#Mann-Whitney U Test (Wilcoxon Rank Sum Test)
wilcox.test(marvel.Male,marvel.Female,alternative = "greater", mu=0)
```

  The results in R provided a p-value of 0.009957 and since this is < 0.05 we reject $H_0$. Therefore, there is evidence that the mean combat score of male heroes is greater than that of female heroes.

# Summary {#sec:Sum}

The final model is$Y_{Combat}=0.046* X_{Height}+0.724* X_{Intelligence}+0.135* X_{Durability} + \epsilon$. That means there are three statistical significant characteristics, which are height, intelligence and durability, and these variables have a positive effect on the combat power. To be specific, when increasing height by one unit, combat increases by 0.046. When increasing intelligence score by one unit, the combat score increases by 0.724, and increasing durability by one unit increases combat score by 0.135. In Addition, the adjusted $R^2$ is 90.57%, so it is already quite plausible to build a simple linear model here. Finally, a non parametric hypothesis test finds that the combat score of male marvel heroes is significantly greater than that of females.


















